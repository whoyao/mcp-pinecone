# Server-Sent Events (SSE) æ”¯æŒ

è¿™ä¸ª MCP Pinecone æœåŠ¡å™¨ç°åœ¨æ”¯æŒ Server-Sent Events (SSE)ï¼Œæä¾›æµå¼å“åº”å’Œå®æ—¶è¿›åº¦æ›´æ–°ã€‚

## åŠŸèƒ½ç‰¹æ€§

### ğŸš€ SSE æ”¯æŒ
- **æµå¼å“åº”**: å®æ—¶ä¼ è¾“æœç´¢ç»“æœå’Œè¿›åº¦æ›´æ–°
- **è¿›åº¦æŒ‡ç¤º**: æ˜¾ç¤ºæ¯ä¸ªå¤„ç†æ­¥éª¤çš„å®æ—¶çŠ¶æ€
- **å¼‚æ­¥å¤„ç†**: éé˜»å¡çš„å“åº”å¤„ç†
- **å®æ—¶åé¦ˆ**: å®¢æˆ·ç«¯å¯ä»¥ç«‹å³çœ‹åˆ°å¤„ç†è¿›åº¦

### ğŸ“¡ æµå¼å·¥å…·

1. **`semantic-search-stream`** - æµå¼è¯­ä¹‰æœç´¢
   - å®æ—¶æ˜¾ç¤ºæœç´¢è¿›åº¦
   - é€ä¸ªè¿”å›æœç´¢ç»“æœ
   - æ˜¾ç¤ºç›¸ä¼¼åº¦åˆ†æ•°å’Œå…ƒæ•°æ®

2. **`pinecone-stats-stream`** - æµå¼ç»Ÿè®¡ä¿¡æ¯
   - é€æ­¥æ˜¾ç¤ºç´¢å¼•ç»Ÿè®¡
   - å®æ—¶æ›´æ–°æ•°æ®
   - è¯¦ç»†çš„ç»Ÿè®¡ä¿¡æ¯

3. **`process-document-stream`** - æµå¼æ–‡æ¡£å¤„ç†
   - æ˜¾ç¤ºåˆ†å—è¿›åº¦
   - å®æ—¶åµŒå…¥ç”ŸæˆçŠ¶æ€
   - ä¸Šä¼ è¿›åº¦æ›´æ–°

## å¿«é€Ÿå¼€å§‹

### 1. å¯åŠ¨ SSE æœåŠ¡å™¨

```bash
# ä½¿ç”¨å¯åŠ¨è„šæœ¬
python start_sse_server.py

# æˆ–ç›´æ¥è¿è¡Œ
python -m src.mcp_pinecone.server_sse
```

### 2. æµ‹è¯• SSE åŠŸèƒ½

```bash
# è¿è¡Œ SSE æ¼”ç¤º
python test_sse.py

# è¿è¡Œå®¢æˆ·ç«¯ç¤ºä¾‹
python sse_client_example.py
```

### 3. æŸ¥çœ‹æµå¼å“åº”

SSE æœåŠ¡å™¨ä¼šæä¾›ä»¥ä¸‹ç±»å‹çš„æµå¼å“åº”ï¼š

```
ğŸ” Starting semantic search...
ğŸ§  Generating embeddings for query...
ğŸ“¡ Searching Pinecone index...
âœ… Found 3 results

ğŸ“„ Result 1:
   Similarity: 0.892
   Document ID: doc-001
   Content: Machine learning is a subset of artificial intelligence...
----------------------------------------

ğŸ“„ Result 2:
   Similarity: 0.756
   Document ID: doc-002
   Content: Deep learning uses neural networks...
----------------------------------------

ğŸ‰ Search completed!
```

## æŠ€æœ¯å®ç°

### æœåŠ¡å™¨ç«¯ (server_sse.py)

```python
@server.call_tool()
async def handle_call_tool(
    name: str, arguments: dict | None
) -> AsyncGenerator[types.TextContent, None]:
    """å¼‚æ­¥ç”Ÿæˆå™¨ï¼Œæ”¯æŒæµå¼å“åº”"""
    if name == "semantic-search-stream":
        async for content in semantic_search_stream(arguments, pinecone_client):
            yield content
```

### å®¢æˆ·ç«¯ç¤ºä¾‹

```python
async def call_streaming_tool(self, tool_name: str, arguments: dict):
    """è°ƒç”¨æµå¼å·¥å…·å¹¶æ¥æ”¶å“åº”"""
    async for chunk in self.call_streaming_tool(
        "semantic-search-stream",
        {"query": "machine learning", "stream": True}
    ):
        print(chunk, end='', flush=True)
```

## é…ç½®é€‰é¡¹

### ç¯å¢ƒå˜é‡

```bash
# å¿…éœ€çš„ API å¯†é’¥
OPENAI_API_KEY=your_openai_api_key_here
PINECONE_API_KEY=your_pinecone_api_key_here

# å¯é€‰çš„é…ç½®
PINECONE_INDEX_NAME=mcp-pinecone-index
DEBUG=false
```

### å·¥å…·å‚æ•°

æ¯ä¸ªæµå¼å·¥å…·éƒ½æ”¯æŒä»¥ä¸‹å‚æ•°ï¼š

- `stream`: å¸ƒå°”å€¼ï¼Œæ§åˆ¶æ˜¯å¦å¯ç”¨æµå¼å“åº” (é»˜è®¤: true)
- å…¶ä»–å‚æ•°ä¸åŸå§‹å·¥å…·ç›¸åŒ

## ä½¿ç”¨ç¤ºä¾‹

### 1. æµå¼æœç´¢

```python
# å®¢æˆ·ç«¯è°ƒç”¨
async for response in client.call_streaming_tool(
    "semantic-search-stream",
    {
        "query": "artificial intelligence",
        "top_k": 5,
        "stream": True
    }
):
    print(response, end='', flush=True)
```

### 2. æµå¼ç»Ÿè®¡

```python
# è·å–æµå¼ç»Ÿè®¡ä¿¡æ¯
async for response in client.call_streaming_tool(
    "pinecone-stats-stream",
    {"stream": True}
):
    print(response, end='', flush=True)
```

### 3. æµå¼æ–‡æ¡£å¤„ç†

```python
# å¤„ç†æ–‡æ¡£å¹¶æ˜¾ç¤ºè¿›åº¦
async for response in client.call_streaming_tool(
    "process-document-stream",
    {
        "document_id": "my-doc",
        "text": "Document content...",
        "metadata": {"category": "AI"},
        "stream": True
    }
):
    print(response, end='', flush=True)
```

## æ€§èƒ½ä¼˜åŠ¿

### ğŸš€ å“åº”é€Ÿåº¦
- **å³æ—¶åé¦ˆ**: ç”¨æˆ·ç«‹å³çœ‹åˆ°å¤„ç†å¼€å§‹
- **æ¸è¿›å¼æ˜¾ç¤º**: ç»“æœé€æ­¥æ˜¾ç¤ºï¼Œæ— éœ€ç­‰å¾…å…¨éƒ¨å®Œæˆ
- **æ›´å¥½çš„ç”¨æˆ·ä½“éªŒ**: é¿å…é•¿æ—¶é—´ç­‰å¾…

### ğŸ“Š èµ„æºåˆ©ç”¨
- **å¼‚æ­¥å¤„ç†**: éé˜»å¡çš„å“åº”å¤„ç†
- **å†…å­˜æ•ˆç‡**: æµå¼å¤„ç†å‡å°‘å†…å­˜å ç”¨
- **å¯æ‰©å±•æ€§**: æ”¯æŒå¤§é‡å¹¶å‘è¯·æ±‚

## é”™è¯¯å¤„ç†

### æœåŠ¡å™¨ç«¯é”™è¯¯å¤„ç†

```python
async def semantic_search_stream(arguments, pinecone_client):
    try:
        # å¤„ç†é€»è¾‘
        yield types.TextContent(type="text", text="å¤„ç†ä¸­...")
    except Exception as e:
        yield types.TextContent(type="text", text=f"âŒ é”™è¯¯: {str(e)}")
```

### å®¢æˆ·ç«¯é”™è¯¯å¤„ç†

```python
try:
    async for response in client.call_streaming_tool(...):
        print(response, end='', flush=True)
except Exception as e:
    print(f"è¿æ¥é”™è¯¯: {e}")
```

## è°ƒè¯•å’Œç›‘æ§

### å¯ç”¨è°ƒè¯•æ—¥å¿—

```python
import logging
logging.basicConfig(level=logging.DEBUG)
```

### ç›‘æ§æµå¼å“åº”

```python
async def monitor_streaming():
    start_time = time.time()
    chunk_count = 0
    
    async for chunk in client.call_streaming_tool(...):
        chunk_count += 1
        print(f"Chunk {chunk_count}: {len(chunk)} chars")
    
    duration = time.time() - start_time
    print(f"Total: {chunk_count} chunks in {duration:.2f}s")
```

## æœ€ä½³å®è·µ

### 1. é”™è¯¯å¤„ç†
- å§‹ç»ˆåŒ…å«é€‚å½“çš„é”™è¯¯å¤„ç†
- æä¾›æœ‰æ„ä¹‰çš„é”™è¯¯æ¶ˆæ¯
- å®ç°é‡è¯•æœºåˆ¶

### 2. æ€§èƒ½ä¼˜åŒ–
- ä½¿ç”¨é€‚å½“çš„å»¶è¿Ÿæ—¶é—´
- é¿å…è¿‡å¤§çš„å“åº”å—
- ç›‘æ§å†…å­˜ä½¿ç”¨

### 3. ç”¨æˆ·ä½“éªŒ
- æä¾›æ¸…æ™°çš„è¿›åº¦æŒ‡ç¤º
- ä½¿ç”¨æœ‰æ„ä¹‰çš„çŠ¶æ€æ¶ˆæ¯
- ä¿æŒå“åº”çš„ä¸€è‡´æ€§

## æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **è¿æ¥è¶…æ—¶**
   - æ£€æŸ¥ç½‘ç»œè¿æ¥
   - å¢åŠ è¶…æ—¶æ—¶é—´
   - éªŒè¯æœåŠ¡å™¨çŠ¶æ€

2. **æµå¼å“åº”ä¸­æ–­**
   - æ£€æŸ¥å®¢æˆ·ç«¯å®ç°
   - éªŒè¯ SSE æ”¯æŒ
   - æŸ¥çœ‹æœåŠ¡å™¨æ—¥å¿—

3. **æ€§èƒ½é—®é¢˜**
   - ç›‘æ§èµ„æºä½¿ç”¨
   - ä¼˜åŒ–æŸ¥è¯¢å‚æ•°
   - è°ƒæ•´å»¶è¿Ÿæ—¶é—´

### è°ƒè¯•æ­¥éª¤

1. æ£€æŸ¥ç¯å¢ƒå˜é‡
2. éªŒè¯ API å¯†é’¥
3. æŸ¥çœ‹æœåŠ¡å™¨æ—¥å¿—
4. æµ‹è¯•ç½‘ç»œè¿æ¥
5. éªŒè¯å®¢æˆ·ç«¯å®ç°

## æœªæ¥æ”¹è¿›

### è®¡åˆ’åŠŸèƒ½
- [ ] WebSocket æ”¯æŒ
- [ ] å®æ—¶é€šçŸ¥
- [ ] æ‰¹é‡æµå¼å¤„ç†
- [ ] æ€§èƒ½ç›‘æ§
- [ ] è‡ªåŠ¨é‡è¿æœºåˆ¶

### æ‰©å±•æ€§
- [ ] æ’ä»¶ç³»ç»Ÿ
- [ ] è‡ªå®šä¹‰æµå¼å¤„ç†å™¨
- [ ] å¤šç§Ÿæˆ·æ”¯æŒ
- [ ] è´Ÿè½½å‡è¡¡

## æ€»ç»“

SSE æ”¯æŒä¸º MCP Pinecone æœåŠ¡å™¨æä¾›äº†å¼ºå¤§çš„æµå¼å“åº”èƒ½åŠ›ï¼Œæ˜¾è‘—æ”¹å–„äº†ç”¨æˆ·ä½“éªŒå’Œç³»ç»Ÿæ€§èƒ½ã€‚é€šè¿‡å®æ—¶è¿›åº¦æ›´æ–°å’Œæ¸è¿›å¼ç»“æœæ˜¾ç¤ºï¼Œç”¨æˆ·å¯ä»¥æ›´å¥½åœ°äº†è§£å¤„ç†çŠ¶æ€å¹¶è·å¾—æ›´å¿«çš„å“åº”åé¦ˆã€‚ 