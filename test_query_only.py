#!/usr/bin/env python3
"""
Simple query test script - Only tests search/query functionality
No data insertion, just queries existing data in your Pinecone index
"""

import os
import logging
from dotenv import load_dotenv
from src.mcp_pinecone.pinecone import PineconeClient

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(message)s')
logger = logging.getLogger(__name__)

# Load environment variables
load_dotenv()

def quick_query_test():
    """Quick test of query functionality"""
    try:
        # Check environment variables
        if not os.getenv("OPENAI_API_KEY"):
            print("âŒ OPENAI_API_KEY environment variable is required")
            return False
        
        if not os.getenv("PINECONE_API_KEY"):
            print("âŒ PINECONE_API_KEY environment variable is required")
            return False
        
        print("ğŸ” åˆå§‹åŒ– Pinecone å®¢æˆ·ç«¯...")
        client = PineconeClient()
        print("âœ… å®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
        
        # Get index statistics first
        print("\nğŸ“Š è·å–ç´¢å¼•ç»Ÿè®¡ä¿¡æ¯...")
        stats = client.stats()
        total_vectors = stats.get('total_vector_count', 0)
        print(f"ç´¢å¼•ä¸­çš„æ€»å‘é‡æ•°: {total_vectors}")
        
        if total_vectors == 0:
            print("âš ï¸  ç´¢å¼•ä¸­æ²¡æœ‰æ•°æ®ï¼Œæ— æ³•è¿›è¡ŒæŸ¥è¯¢æµ‹è¯•")
            print("è¯·å…ˆæ·»åŠ ä¸€äº›æ•°æ®åˆ°ç´¢å¼•ä¸­ï¼Œæˆ–è€…è¿è¡Œ example_usage.py æ¥æ·»åŠ æµ‹è¯•æ•°æ®")
            return False
        
        # Test queries
        test_queries = [
            "machine learning",
            "artificial intelligence", 
            "data science",
            "neural networks",
            "deep learning"
        ]
        
        print(f"\nğŸ” å¼€å§‹æŸ¥è¯¢æµ‹è¯• (ç´¢å¼•ä¸­æœ‰ {total_vectors} ä¸ªå‘é‡)...")
        
        for i, query in enumerate(test_queries, 1):
            print(f"\n--- æŸ¥è¯¢ {i}: '{query}' ---")
            
            try:
                results = client.search_records(query, top_k=3)
                matches = results.get("matches", [])
                
                if matches:
                    print(f"æ‰¾åˆ° {len(matches)} ä¸ªåŒ¹é…ç»“æœ:")
                    for j, match in enumerate(matches, 1):
                        score = match.get("score", 0)
                        doc_id = match.get("id", "")
                        metadata = match.get("metadata", {})
                        text = metadata.get("text", "")
                        
                        # Truncate text for display
                        display_text = text[:80] + "..." if len(text) > 80 else text
                        
                        print(f"  {j}. ç›¸ä¼¼åº¦: {score:.3f} | ID: {doc_id}")
                        print(f"     å†…å®¹: {display_text}")
                        
                        # Show metadata if available
                        if metadata and len(metadata) > 1:  # More than just 'text'
                            meta_keys = [k for k in metadata.keys() if k != 'text']
                            if meta_keys:
                                print(f"     å…ƒæ•°æ®: {meta_keys}")
                else:
                    print("  æ²¡æœ‰æ‰¾åˆ°åŒ¹é…ç»“æœ")
                    
            except Exception as e:
                print(f"  âŒ æŸ¥è¯¢å¤±è´¥: {e}")
        
        print("\nâœ… æŸ¥è¯¢æµ‹è¯•å®Œæˆï¼")
        return True
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_embedding_only():
    """Test only embedding generation without any Pinecone operations"""
    try:
        print("ğŸ§  æµ‹è¯• OpenAI åµŒå…¥ç”Ÿæˆ...")
        
        client = PineconeClient()
        
        test_texts = [
            "Hello world",
            "Machine learning is fascinating",
            "è¿™æ˜¯ä¸€ä¸ªä¸­æ–‡æµ‹è¯•"
        ]
        
        for i, text in enumerate(test_texts, 1):
            print(f"æµ‹è¯• {i}: ç”Ÿæˆæ–‡æœ¬åµŒå…¥...")
            embeddings = client.generate_embeddings(text)
            print(f"  âœ… ç”Ÿæˆäº† {len(embeddings)} ç»´åµŒå…¥å‘é‡")
            print(f"  å‰3ä¸ªå€¼: {embeddings[:3]}")
        
        print("âœ… åµŒå…¥ç”Ÿæˆæµ‹è¯•å®Œæˆï¼")
        return True
        
    except Exception as e:
        print(f"âŒ åµŒå…¥ç”Ÿæˆæµ‹è¯•å¤±è´¥: {e}")
        return False

def main():
    """Main function"""
    print("=" * 60)
    print("Pinecone æŸ¥è¯¢åŠŸèƒ½æµ‹è¯•")
    print("=" * 60)
    print("æ­¤è„šæœ¬åªæµ‹è¯•æŸ¥è¯¢åŠŸèƒ½ï¼Œä¸ä¼šæ’å…¥æ–°æ•°æ®")
    print()
    
    # Test embedding generation first
    print("1ï¸âƒ£ æµ‹è¯• OpenAI åµŒå…¥ç”Ÿæˆ...")
    embedding_success = test_embedding_only()
    
    if embedding_success:
        print("\n2ï¸âƒ£ æµ‹è¯• Pinecone æŸ¥è¯¢åŠŸèƒ½...")
        query_success = quick_query_test()
        
        if query_success:
            print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
            print("\nğŸ“‹ æµ‹è¯•æ€»ç»“:")
            print("  âœ… OpenAI åµŒå…¥ç”Ÿæˆ: æ­£å¸¸")
            print("  âœ… Pinecone æŸ¥è¯¢åŠŸèƒ½: æ­£å¸¸")
        else:
            print("\nâš ï¸  æŸ¥è¯¢æµ‹è¯•å¤±è´¥ï¼Œä½†åµŒå…¥ç”Ÿæˆæ­£å¸¸")
            print("å¯èƒ½çš„åŸå› :")
            print("  - ç´¢å¼•ä¸­æ²¡æœ‰æ•°æ®")
            print("  - Pinecone API é…ç½®é—®é¢˜")
            print("  - ç½‘ç»œè¿æ¥é—®é¢˜")
    else:
        print("\nâŒ åµŒå…¥ç”Ÿæˆæµ‹è¯•å¤±è´¥")
        print("è¯·æ£€æŸ¥ OpenAI API é…ç½®")
    
    print("\nğŸ’¡ æç¤º:")
    print("  - å¦‚æœç´¢å¼•ä¸ºç©ºï¼Œè¿è¡Œ 'python example_usage.py' æ·»åŠ æµ‹è¯•æ•°æ®")
    print("  - æŸ¥çœ‹è¯¦ç»†æ—¥å¿—: ä¿®æ”¹ logging.basicConfig(level=logging.DEBUG)")

if __name__ == "__main__":
    main() 